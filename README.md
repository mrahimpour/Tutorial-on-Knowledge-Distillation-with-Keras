# Tutorial-on-Knowledge-Distillation-with-Keras
This tutorial aims to introduce the concept of knowledge distillation and its application in medical image processing. 

# What is knowledge distillation:
Knowledge distillation refers to any type of training which transfers knowledgefrom a complex or deep model to a simple or compact model.
